# Rusty Recognition - MNIST with Metal

A high-performance MNIST digit recognition project implemented in Rust with custom Metal GPU kernels for Apple Silicon.

## Project Structure

```
mnist-metal/
â”œâ”€â”€ Cargo.toml                  # Workspace configuration
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ core/                   # Device-agnostic ML abstractions
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ backend.rs      # Backend trait and CPU implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ tensor.rs       # Tensor abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ ops_cpu/        # CPU operations (matmul, relu, softmax)
â”‚   â”‚   â”‚   â”œâ”€â”€ nn/             # Neural network layers and models
â”‚   â”‚   â”‚   â”œâ”€â”€ data/           # MNIST data loading
â”‚   â”‚   â”‚   â””â”€â”€ train.rs        # Training orchestration
â”‚   â”‚   â””â”€â”€ Cargo.toml
â”‚   â”œâ”€â”€ gpu_metal/              # Metal GPU implementation
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ device.rs       # Metal device and pipeline management
â”‚   â”‚   â”‚   â”œâ”€â”€ buffer.rs       # GPU buffer management
â”‚   â”‚   â”‚   â”œâ”€â”€ backend.rs      # Metal backend implementation
â”‚   â”‚   â”‚   â””â”€â”€ ops/            # GPU operation wrappers
â”‚   â”‚   â”œâ”€â”€ shaders/
â”‚   â”‚   â”‚   â””â”€â”€ kernels.metal   # Metal Shading Language kernels
â”‚   â”‚   â””â”€â”€ Cargo.toml
â”‚   â””â”€â”€ bin/                    # CLI application
â”‚       â”œâ”€â”€ src/main.rs         # Main CLI with training commands
â”‚       â””â”€â”€ Cargo.toml
â”œâ”€â”€ data/                       # MNIST dataset files (download separately)
â”œâ”€â”€ checkpoints/                # Saved model checkpoints
â””â”€â”€ results/                    # Training metrics and timing data
```

## Architecture Patterns

The codebase implements several design patterns for clean, extensible ML infrastructure:

- **Backend Bridge**: Decouples models from compute devices (CPU/GPU)
- **Strategy**: Interchangeable backends and optimizers  
- **Composite**: Sequential models built from reusable layers
- **Builder**: Fluent API for model construction
- **Template Method**: Standardized training loop with customizable callbacks
- **Observer**: Pluggable metrics collection and logging

## Features

- âœ… CPU baseline implementation with naive operations
- âœ… Metal GPU backend with custom MSL kernels
- âœ… Modular tensor abstraction supporting multiple backends
- âœ… MLP (Multi-Layer Perceptron) implementation
- ðŸš§ CNN (Convolutional Neural Network) with im2col + tiled matmul
- ðŸš§ Optimized tiled matrix multiplication kernels
- ðŸš§ Fused softmax + cross-entropy kernels
- âœ… SGD optimizer with momentum support
- âœ… CLI with training and evaluation modes

## Quick Start

### Prerequisites

- Rust 1.75+ with Cargo
- macOS with Apple Silicon (for Metal support)
- MNIST dataset files (see Data Setup below)

### Build

```bash
cargo build --release
```

### Data Setup

Download MNIST dataset files and place in `data/` directory:
- `train-images-idx3-ubyte`
- `train-labels-idx1-ubyte`  
- `t10k-images-idx3-ubyte`
- `t10k-labels-idx1-ubyte`

### Training Commands

```bash
# CPU MLP training
cargo run --release -- cpu-mlp --epochs 3 --batch 64 --lr 0.01

# GPU MLP training  
cargo run --release -- gpu-mlp --epochs 3 --batch 256 --lr 0.01

# GPU CNN training
cargo run --release -- gpu-cnn --epochs 5 --batch 256 --lr 0.01

# Model evaluation
cargo run --release -- eval --ckpt checkpoints/cnn_best.ckpt
```

## Performance Goals

- **Accuracy**: â‰¥97% test accuracy (CPU MLP), â‰¥98.5% (GPU CNN)
- **Speedup**: â‰¥5Ã— GPU inference vs CPU for batchâ‰¥256
- **Training**: â‰¥2Ã— GPU vs CPU epoch time

## Development Status

This project is currently in **Milestone M0** (Repo Scaffold). The basic structure is complete and ready for implementation of CPU operations and Metal kernels.

### Next Steps (M1 - CPU Baseline)
1. Implement CPU matrix multiplication and neural network training
2. Add MNIST data loading and preprocessing  
3. Create working MLP that achieves â‰¥97% accuracy
4. Set up training metrics collection

### Planned Milestones
- **M1**: CPU baseline MLP training
- **M2**: Metal GPU runtime and simple kernels (ReLU)
- **M3**: Tiled matrix multiplication on GPU
- **M4**: Full GPU backpropagation pipeline
- **M5**: CNN implementation with im2col convolution
- **M6**: Performance optimization and demo polish

## Metal Kernels

Custom MSL kernels implemented:
- `relu_forward` / `drelu`: Element-wise ReLU activation
- `naive_gemm`: Basic matrix multiplication
- `matmul_tiled`: Optimized tiled GEMM with threadgroup memory
- `softmax_xent`: Fused softmax + cross-entropy loss
- `sgd_step`: SGD parameter updates with momentum

## License

MIT OR Apache-2.0